# FLUJO DE IMÃGENES EN EL PROYECTO

## ğŸ“¸ Dos flujos de imagen separados:

### 1ï¸âƒ£ IMAGEN DEL AGENTE (DRL Input)
```
CARLA Sensor â†’ 640Ã—480 RGB â†’ Grayscale â†’ 11Ã—11 â†’ Normalizar â†’ Flatten â†’ [121 valores]
                                                                              â†“
                                                                    Concatenar con Ï†t, dt
                                                                              â†“
                                                                        [123 valores]
                                                                              â†“
                                                                         Red Neuronal
```

**CaracterÃ­sticas:**
- Captura: 640Ã—480 RGB desde sensor frontal
- Procesa: Convierte a B/W y reduce a 11Ã—11
- PropÃ³sito: Input del agente DRL (muy eficiente)
- Archivo: `src/env/base_env.py` â†’ `post_process_image()`

### 2ï¸âƒ£ IMAGEN DE VISUALIZACIÃ“N (Render Output)
```
CARLA Last Observation â†’ 336Ã—336 RGB â†’ Guardar PNG
```

**CaracterÃ­sticas:**
- TamaÃ±o: 336Ã—336 pÃ­xeles (para que humanos puedan ver)
- PropÃ³sito: Debug y visualizaciÃ³n
- NO es lo que el agente ve
- Carpeta: `render_output/frame_XXXX.png`
- Archivo: `src/env/carla_env.py` â†’ `render()`

---

## ğŸ” CONFIGURACIÃ“N ACTUAL (Paper PÃ©rez-Gil et al. 2022)

### Sensor de CÃ¡mara RGB:
```python
"rgb_camera": {
    "type": "sensor.camera.rgb",
    "transform": "1.5,0.0,1.5,0.0,0.0,0.0",  # Frontal, parabrisas
    "image_size_x": "640",  # âœ… Paper: Original 640Ã—480
    "image_size_y": "480",  # âœ… Paper: Original 640Ã—480
    "fov": "90",            # Campo de visiÃ³n 90Â°
    "size": 11              # âœ… Paper: Target resize 11Ã—11
}
```

### Procesamiento (post_process_image):
1. **Captura**: CARLA devuelve 640Ã—480 RGB
2. **Grayscale**: RGB â†’ B/W (cv2.COLOR_RGB2GRAY)
3. **Resize**: 640Ã—480 â†’ 11Ã—11 (cv2.resize)
4. **Normalizar**: [0,255] â†’ [-1,1]
5. **Flatten**: (11,11,1) â†’ (121,)
6. **Concatenar**: [121 pÃ­xeles] + [Ï†t] + [dt] = [123 valores]

### ReducciÃ³n de datos:
```
640 Ã— 480 = 307,200 pÃ­xeles
11 Ã— 11 = 121 pÃ­xeles
ReducciÃ³n: 2,539Ã— mÃ¡s pequeÃ±o
```

---

## âš ï¸ IMPORTANTE: Â¿Por quÃ© 11Ã—11 se ve "raro"?

**ES INTENCIONAL segÃºn el paper:**

> "This proposed agent reshapes the B/W frontal image, taken from the vehicle,
> from 640x480 pixels to 11x11, reducing the amount of data from 300k to 121."
> â€” PÃ©rez-Gil et al. (2022), SecciÃ³n 5.1

**Ventajas:**
1. âœ… ReducciÃ³n dramÃ¡tica del espacio de estados
2. âœ… Entrenamiento mÃ¡s rÃ¡pido (menos parÃ¡metros)
3. âœ… Suficiente informaciÃ³n para navegaciÃ³n bÃ¡sica
4. âœ… Funciona bien segÃºn resultados del paper

**"Desventajas" (en realidad no lo son):**
- ğŸ”² Imagen MUY pixelada (solo 11Ã—11 = 121 cuadrados)
- ğŸ”² DifÃ­cil de reconocer para humanos
- ğŸ”² PÃ©rdida de detalles finos

**Pero el agente DRL no necesita ver como humanos!**

---

## ğŸ¯ RESUMEN

Si ves la imagen del agente (11Ã—11) y te parece "rara", **eso es CORRECTO**.
Si ves las imÃ¡genes de render_output (336Ã—336) y se ven raras, **eso es diferente**.

Â¿CuÃ¡l de las dos es la que te parece rara?
